---
layout: redirect
title: "Last Week in AI #328"
excerpt: "AWS unveils Trainium3 and teases Nvidia-friendly Trainium4 üîß‚ö°, Mistral drops open-weight frontier and tiny edge-ready models üåçü§ñ, DeepSeek touts GPT-5-level reasoning üß†üìê, Runway‚Äôs Gen-4.5 tops video benchmarks üé¨üèÜ, Black Forest Labs raises $300M for Flux 2 üì∏üöÄ, and more!"
image: 
  feature: assets/img/digests/328/deepseek-whale.jpg
  credit: <a href="<Image Source Link>"> <Author> / <Source Name> </a>
categories: [digests]
permalink: /digests/the-three-hundred-and-twenty-eighth
sidebartoc: true
redirect: https://lastweekin.ai/p/328
---### Top News

#### [Amazon releases an impressive new AI chip and teases an Nvidia-friendly roadmap](https://techcrunch.com/2025/12/02/amazon-releases-an-impressive-new-ai-chip-and-teases-a-nvidia-friendly-roadmap/)
![](https://techcrunch.com/wp-content/uploads/2020/01/GettyImages-1136663877.jpg?resize=1200,800)

At re:Invent 2025, AWS introduced Trainium3 and the Trainium3 UltraServer, claiming major gen-over-gen gains with a strong emphasis on efficiency. The 3 nm Trainium3 chip powers UltraServers with 144 chips each, and AWS says workloads run 4x faster with 4x more memory than the previous generation, for both training and inference. Using AWS‚Äôs homegrown networking, thousands of UltraServers can be linked to scale up to 1 million Trainium3 chips‚Äî10x the prior max cluster size. Energy efficiency is a key selling point, with AWS touting 40% lower energy use per task versus last gen, which should reduce power draw and customer costs. Early adopters including Anthropic, Karakuri, SplashMusic, and Decart have reportedly lowered inference costs with the new hardware.

Looking ahead, AWS previewed Trainium4, now in development, with another sizable performance jump and‚Äîcrucially‚Äîsupport for Nvidia‚Äôs NVLink Fusion interconnect. That would allow future Trainium4 systems to interoperate with Nvidia GPUs while leveraging AWS‚Äôs cost-optimized racks, potentially easing adoption for CUDA-centric AI stacks. The interoperability could make it simpler to extend Nvidia-based workflows onto AWS Trainium infrastructure without leaving the Nvidia ecosystem. No release date was given, but AWS hinted more details may come at next year‚Äôs re:Invent.

#### [Mistral closes in on Big AI rivals with new open-weight frontier and small models](https://techcrunch.com/2025/12/02/mistral-closes-in-on-big-ai-rivals-with-mistral-3-open-weight-frontier-and-small-models/)
![](https://techcrunch.com/wp-content/uploads/2024/05/GettyImages-2147859992-e1713960898378.webp?resize=1200,676)

Mistral unveiled the Mistral 3 family: one open-weight frontier model (Mistral Large 3) plus nine smaller ‚ÄúMinistral 3‚Äù models spanning 14B, 8B, and 3B parameters in Base, Instruct, and Reasoning variants. Large 3 is a multimodal, multilingual model using a granular Mixture of Experts with 41B active parameters out of 675B total and a 256k context window, positioned for document analysis, coding, AI assistants, and workflow automation. It joins the small cohort of open frontier models that integrate vision and language in one system, comparable to Llama 3 and Qwen3-Omni, rather than pairing separate LLM and vision models. Mistral argues initial benchmarks understate its value because customization and fine-tuning on enterprise data often close the gap with closed models.

On the deployment front, Ministral 3 targets practicality: all variants support vision, 128k‚Äì256k context windows, and multilingual use, and are designed to run offline on a single GPU for on-prem, laptops, edge devices, or robots. Mistral claims the small models can match or outperform larger closed systems after fine-tuning, with higher efficiency and fewer tokens generated for equivalent tasks. The company emphasizes cost and reliability versus API-only closed providers and is pushing into ‚Äúphysical AI‚Äù with integrations in robots, drones, and vehicles. Active collaborations include Singapore‚Äôs HTX (robots, cybersecurity, fire safety), Helsing (vision-language-action for drones), and Stellantis (in-car assistant).

#### [DeepSeek Releases New Reasoning Models to Match GPT-5, Rival Gemini 3 Pro](https://analyticsindiamag.com/ai-news-updates/deepseek-releases-new-reasoning-models-to-match-gpt-5-rival-gemini-3-pro/)
Related:
 * [DeepSeek Releases New Reasoning Models to Take On ChatGPT and Gemini](https://www.cnet.com/tech/services-and-software/deepseek-releases-new-reasoning-models-to-take-on-chatgpt-and-gemini/)
 * [Deepseek 3.2 : New AI Model is Faster, Cheaper and Smarter](https://www.geeky-gadgets.com/deepseek-3-2-sparse-attention-optimization/)

![](https://analyticsindiamag.com/wp-content/uploads/2025/01/deepseek-whale.jpg)

DeepSeek released two open-source reasoning-first models, DeepSeek-V3.2 and DeepSeek-V3.2-Speciale, on Hugging Face, with V3.2 live across its app, web, and API, and Speciale temporarily available via API until December 15, 2025. V3.2 succeeds V3.2-Exp and targets ‚ÄúGPT-5 level performance,‚Äù balancing inference efficiency with long-context handling while integrating ‚ÄúThinking in Tool-Use‚Äù so structured reasoning operates within and alongside external tool calls; Speciale is priced the same but lacks tool-call support. DeepSeek says Speciale rivals Gemini 3.0 Pro and achieves gold-level (expert) results across competitive benchmarks like IMO, CMO, and ICPC World Finals; other reports add wins at IMO 2025 and IOI. The release expands DeepSeek‚Äôs agent-training approach with a synthetic dataset of 1,800+ environments and 85,000 complex instructions, and the company also highlighted its open-weight DeepSeekMath-V2 for theorem proving and gold-level IMO 2025 scores.

Earlier coverage of V3.2-Exp emphasized sparse attention as a key technical innovation for speed and cost, citing over 50% API cost reductions and improved computational efficiency, with strengths in logical/quantitative reasoning and creative tasks (e.g., SVG animation, SaaS landing pages, browser-based OS UIs). Those reports also note trade-offs: limitations on very long-context tasks and occasional issues with intricate icon generation, with future refinement planned in a DeepSeek R2 line. One report claims V3.2 has 685 billion parameters, underscoring heavy server requirements despite DeepSeek‚Äôs open-source stance. Practically, V3.2 keeps API usage patterns consistent with prior versions, while Speciale is positioned for high-end reasoning workloads and benchmark parity or superiority versus GPT-5 High and Gemini 3.0 Pro, according to the company.

#### [Runway rolls out new AI video model that beats Google, OpenAI in key benchmark](https://www.cnbc.com/2025/12/01/runway-gen-4-5-video-model-google-open-ai.html)
![](https://image.cnbcfm.com/api/v1/image/108162827-1750712201805-gettyimages-2207801548-AA_04042025_2159477.jpeg?v=1764542788&w=1920&h=1080)

Runway launched Gen-4.5, a new text-to-video model that generates high-definition clips from written prompts specifying motion and action. The company says the model excels at physics consistency, realistic human motion, coherent camera movements, and cause-and-effect reasoning, addressing common failure modes in video generation like object drift and temporal flicker. In blind A/B comparisons on the independent Video Arena benchmark by Artificial Analysis, Gen-4.5 ranks No. 1 overall for text-to-video quality. Voters compare pairs of outputs without seeing model identities, and Gen-4.5 beat competitors across categories emphasizing motion fidelity and scene coherence.

On the current leaderboard, Google‚Äôs Veo 3 sits at No. 2, while OpenAI‚Äôs Sora 2 Pro is at No. 7, highlighting a notable gap in head-to-head user preference for Runway‚Äôs outputs. Runway emphasizes that a small, focused team‚Äîabout 100 employees‚Äîdeveloped the model, underscoring efficiency in training and iteration against much larger rivals. Key capabilities include better handling of human biomechanics, consistent object interactions under physical constraints, and smoother, controllable camera paths. CEO Crist√≥bal Valenzuela framed the result as evidence that careful model design and evaluation can outpace scale alone in video generation quality.

#### [Black Forest Labs raises $300M at $3.25B valuation](https://techcrunch.com/2025/12/01/black-forest-labs-raises-300m-at-3-25b-valuation/)
![](https://techcrunch.com/wp-content/uploads/2025/12/6844c7ed531e3aa09958eea8a9deae8bdabd0b54-3721x2798-1.png?resize=1200,902)

Black Forest Labs raised $300 million in a Series B at a $3.25 billion valuation, co-led by Salesforce Ventures and Anjney Midha (AMP), with participation from a16z, NVIDIA, Northzone, Creandum, Earlybird VC, BroadLight Capital, General Catalyst, Temasek, Bain Capital Ventures, Air Street Capital, Visionaries Club, Canva, and Figma Ventures. The company said the funds will go toward research and development. Black Forest Labs builds foundation AI models for image generation and editing and has seen rapid adoption since launching in August 2024. Its models power image features in products from Adobe, fal.ai, Picsart, ElevenLabs, VSCO, Vercel, and previously underpinned image generation in Elon Musk‚Äôs Grok chatbot.

Recently, the startup released Flux 2, an image generation model with improved text and image rendering, support for up to 10 reference images to preserve style and tone, and output up to 4K resolution. Flux 2 emphasizes better text fidelity within images, a common shortcoming of prior models, while adding multi-image conditioning for consistent aesthetics. The company‚Äôs founding team‚ÄîRobin Rombach, Patrick Esser, and Andreas Blattmann‚Äîpreviously helped create Stability AI‚Äôs Stable Diffusion, underscoring their experience in diffusion-based generative models. Black Forest Labs‚Äô fast growth and large customer integrations position Flux 2 as a competitive alternative in the image model space.



### Other News
#### Tools
![](https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/arc-prize-leaderboard-1.png?quality=90&strip=all&crop=0%2C5.6289527888428%2C100%2C88.742094422314&w=1200)

[Gemini 3 Deep Think is rolling out now.](https://www.theverge.com/news/838715/gemini-3-deep-think-is-rolling-out-now). Available only to Google AI Ultra subscribers in the Gemini app, Deep Think mode tops the ARC-AGI-2 reasoning benchmark and targets complex math, science, and logic problems.

[Nvidia announces new open AI models and tools for autonomous driving research](https://techcrunch.com/2025/12/01/nvidia-announces-new-open-ai-models-and-tools-for-autonomous-driving-research/). Alongside the releases, Nvidia published a Cosmos Cookbook on GitHub with guides, inference resources, and workflows to help developers curate data, generate synthetic data, and fine-tune Cosmos-based models for autonomous driving research.

[Black Forest Labs launches Flux.2 AI image models to challenge Nano Banana Pro and Midjourney | VentureBeat](https://venturebeat.com/ai/black-forest-labs-launches-flux-2-ai-image-models-to-challenge-nano-banana). None

[Kling's Video O1 launches as the first all-in-one video model for generation and editing](https://the-decoder.com/klings-video-o1-launches-as-the-first-all-in-one-video-model-for-generation-and-editing/). The model can generate short videos from prompts or references and perform complex edits‚Äîlike swapping subjects, changing weather, or preserving character consistency across shots‚Äîby processing multiple images, videos, and text inputs in a single multimodal prompt.

[Sora and Nano Banana Pro throttled amid soaring demand](https://www.theverge.com/news/831760/openai-google-rate-limit-sora-nano-banana-pro). OpenAI and Google imposed new daily generation limits on free users of Sora and Nano Banana Pro‚Äîsix video gens for Sora and two images for Nano Banana Pro‚Äîwhile keeping subscriber caps unchanged and offering paid add-ons as demand-driven mitigations.

#### Business
![](https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/STK201_SAM_ALTMAN_CVIRGINIA_C.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200)

[OpenAI declares ‚Äòcode red‚Äô as Google catches up in AI race](https://www.theverge.com/news/836212/openai-code-red-chatgpt). Altman ordered a pause on nonessential product work and redirected staff to daily efforts to make ChatGPT faster, more reliable, and better personalized as competitors like Google and Anthropic close the gap.

[OpenAI‚Äôs lead under pressure as rivals start to close the gap](https://www.ft.com/content/8881062d-ff4f-4454-8e9d-d992e8e2c4e3). Executives and engineers at the company face scrutiny as competitors narrow performance and feature differences, prompting questions about strategy and talent retention.

[Altman memo: new OpenAI model coming next week, outperforming Gemini 3](https://the-decoder.com/altman-memo-new-openai-model-coming-next-week-outperforming-gemini-3/). Internal tests cited by CEO Sam Altman claim the model will surpass Gemini 3, and its accelerated launch has prompted OpenAI to reprioritize resources away from advertising, agents, and other projects toward improving ChatGPT and image-generation capabilities.

[Leak confirms OpenAI is preparing ads on ChatGPT for public roll out](https://www.bleepingcomputer.com/news/artificial-intelligence/leak-confirms-openai-is-preparing-ads-on-chatgpt-for-public-roll-out/). Internal beta strings show features like "bazaar content," "search ad," and a "search ads carousel" tied to ChatGPT's search experience, suggesting OpenAI may roll out targeted, personalized ads to its large and rapidly growing user base.

[Anthropic reportedly preparing for one of the largest IPOs ever in race with OpenAI: FT](https://www.cnbc.com/2025/12/03/anthropic-claude-reportedly-preparing-ipo-race-openai-chatgpt-ft-wilson-sonsini-goodrich-rosati.html). The company has held preliminary talks with law firms and banks, pursued a private funding round that could value it above $300 billion, and discussed large commitments from Microsoft and Nvidia while preparing internal IPO-related work.

[Nvidia takes $2 billion stake in Synopsys with expanded computing power partnership](https://www.cnbc.com/2025/12/01/nvidia-takes-2-billion-stake-in-synopsys.html). The investment will fund a multiyear collaboration where Nvidia provides computing resources and joint go-to-market efforts to help Synopsys speed up compute-intensive design and agentic AI engineering while expanding cloud access.

[Anthropic acquires developer tool startup Bun to scale AI coding](https://uk.finance.yahoo.com/news/anthropic-acquires-developer-tool-startup-185940954.html). The acquisition brings Bun's integrated runtime, package management, bundling, and testing tools into Anthropic to help scale and stabilize its Claude Code offering, which has already reached a $1 billion annualized revenue run rate and been adopted by major enterprises.

[OpenAI to acquire Neptune, a startup that helps with AI model training](https://www.cnbc.com/2025/12/03/openai-to-acquire-neptune-an-ai-model-training-assistance-startup.html). The acquisition will bring Neptune's monitoring and debugging tools and its metrics dashboard into OpenAI's training stack, with the startup winding down external services as the companies integrate their work.

[ChatGPT‚Äôs user growth has slowed, report finds](https://techcrunch.com/2025/12/05/chatgpts-user-growth-has-slowed-report-finds/). Sensor Tower data shows ChatGPT still leads in downloads and monthly active users, but its growth has slowed while rival Google Gemini‚Äîboosted by features like the Nano Banana image model and deeper Android integration‚Äîis growing faster and eating into market share.

[Microsoft drops AI sales targets in half after salespeople miss their quotas](https://arstechnica.com/ai/2025/12/microsoft-slashes-ai-sales-growth-targets-as-customers-resist-unproven-agents/). The company lowered internal growth targets for its AI agent products‚Äîcutting some quotas by about half‚Äîafter many salespeople failed to meet ambitious Foundry and Copilot sales goals.

[Elon Musk slashes Tesla Robotaxi fleet goal from 500 to ~60 in Austin](https://electrek.co/2025/11/26/elon-musk-slashes-tesla-robotaxi-fleet-goal-austin/). Instead of the 500 Robotaxis Musk promised for Austin by year-end, Tesla‚Äôs supervised pilot is on track to reach only about 60 vehicles, roughly double the current ~30, highlighting a roughly 90% shortfall versus the target.

[Waymo's testing AVs in four more cities, including Philly](https://www.engadget.com/transportation/evs/waymos-testing-avs-in-four-more-cities-including-philly-161709279.html). The trials involve supervised, human-monitored runs in Philadelphia, Baltimore, St. Louis, and Pittsburgh as a precursor to fully driverless deployments planned after data collection and safety assessments.

[Suno Creates an Entire Spotify Catalog‚Äôs Worth of Music Every Two Weeks, Says Investor Pitch Deck for $250M Fundraise](https://www.billboard.com/pro/suno-creates-spotify-catalog-music-two-weeks-pitch-deck/). Users generate roughly 7 million songs per day on Suno‚Äîa production rate the company says equals Spotify‚Äôs entire catalog every two weeks‚Äîwhile the startup pursues growth through a recent $250 million funding round, heavy compute spending, planned product expansion, and ongoing copyright lawsuits with major labels.

[OpenAI just made another circular deal](https://www.theverge.com/news/835453/openai-ownership-thrive-holdings). The partnership will see OpenAI provide employees, models, products, and services to Thrive Holdings‚Äô portfolio in IT services and accounting, potentially gaining access to company data for model training and future payouts from the private equity firm‚Äôs returns.

[Apple AI chief steps down following Siri setbacks](https://www.theverge.com/news/835466/apple-ai-chief-john-giannandrea-steps-down-siri). He will replace Giannandrea and oversee Apple‚Äôs AI models, ML research, and AI safety as the company works to relaunch an upgraded, more personalized Siri next spring.

[Paris-based AI voice startup Gradium nabs $70M seed](https://techcrunch.com/2025/12/02/paris-based-ai-voice-startup-gradium-nabs-70m-seed/). Founded in September by former Google DeepMind researcher Neil Zeghidour, the startup launched with $70M seed funding from investors including FirstMark, Eurazeo, Xavier Niel, and Eric Schmidt and offers low-latency multilingual audio language models (English, French, German, Spanish, Portuguese) for developers.

[OpenAGI emerges from stealth with an AI agent that it claims crushes OpenAI and Anthropic | VentureBeat](https://venturebeat.com/ai/openagi-emerges-from-stealth-with-an-ai-agent-that-it-claims-crushes-openai). None

#### Research
![](https://wp.technologyreview.com/wp-content/uploads/2025/12/confessions3.jpg?resize=1200,600)

[OpenAI has trained its LLM to confess to bad behavior](https://www.technologyreview.com/2025/12/03/1128740/openai-has-trained-its-llm-to-confess-to-bad-behavior/). Researchers trained GPT-5-Thinking to produce brief three-part "confessions" admitting when it lied, cheated, or took shortcuts in tests‚Äîsuccessfully eliciting admissions in most trials, with limits when the model wasn‚Äôt aware of its misbehavior.

[The Art of Scaling Test-Time Compute for Large Language Models](https://arxiv.org/abs/2512.02008). Experiments with recent models show that optimal test-time scaling depends on each model's post-training method‚Äîmodels trained with GRPO-like algorithms favor short, concise reasoning, while those trained with GSPO-like methods sustain longer traces and benefit from increased inference compute.

[Nemotron-Flash: Towards Latency-Optimal Hybrid Small Language Models](https://arxiv.org/abs/2511.18890). The work combines depth‚Äìwidth scaling, hybrid attention-operator selection via evolutionary search, and weight-norm training tweaks to produce small models that improve latency, throughput, and accuracy trade-offs compared with prior SLMs.

[Feedback Descent: Open-Ended Text Optimization via Pairwise Comparison](https://arxiv.org/abs/2511.07919). The method iteratively uses language models to translate pairwise preferences and textual feedback into targeted edits of text artifacts at inference time, yielding gradient-like optimization in text space across tasks like prompt tuning, visual design, and molecule discovery.

[Adversarial Flow Models](https://arxiv.org/abs/2511.22475). This approach unifies adversarial training with deterministic flow-based transport to enable stable single-step (and multi-step) generation on standard transformer architectures, improving sample quality and training scalability on ImageNet compared to prior consistency-based and flow-matching methods.

[Infinity-RoPE: Action-Controllable Infinite Video Generation Emerges From Autoregressive Self-Rollout](https://arxiv.org/abs/2511.20649). The paper uses a training-free Block-Relativistic RoPE positional encoding plus KV Flush and RoPE Cut inference operators to convert short-horizon autoregressive DiTs into action-controllable, constant-memory infinite-horizon video generators.

[Generalist Large Language Models Outperform Clinical Tools on Medical Benchmarks](https://arxiv.org/abs/2512.01191). The study finds that widely used general-purpose LLMs achieve higher scores than dedicated clinical AI systems across a range of medical tasks, underscoring the importance of independent benchmarking for clinical decision support tools.

#### Concerns
![](https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2169504075.jpg?resize=1200,801)

[Chicago Tribune sues Perplexity](https://techcrunch.com/2025/12/04/chicago-tribune-sues-perplexity/). The Tribune alleges Perplexity scraped and reproduced its articles‚Äîincluding bypassing paywalls and using its content in retrieval-augmented generation‚Äîwithout permission, and has sued for copyright infringement.

[Claude 4.5 Opus' Soul Document](https://simonwillison.net/2025/Dec/2/claude-soul-document/). A 14,000-token "soul overview" used in training Claude 4.5 Opus (confirmed by Anthropic) outlines the model's intended safety-focused values, its supervised learning role, and guidance on issues like prompt injection.

[Waymo to issue software recall over how robotaxis behave around school buses](https://techcrunch.com/2025/12/05/waymo-to-issue-software-recall-over-how-robotaxis-behave-around-school-buses/). Waymo will file a voluntary software recall with federal regulators after updating its code to improve how robotaxis slow and stop around stopped school buses following multiple reported incidents and regulatory scrutiny.

[Feds ask Waymo about robotaxis repeatedly passing school buses in Austin](https://techcrunch.com/2025/12/04/feds-ask-waymo-about-robotaxis-repeatedly-passing-school-buses-in-austin/). NHTSA's Office of Defects Investigation requested detailed information and documentation from Waymo about its fifth-generation self-driving system and recent software fixes after Austin schools reported 19 instances this year of Waymo robotaxis illegally passing stopped school buses; the agency is probing whether Waymo halted operations, fixed the issue, or needs a recall.

[Google is experimentally replacing news headlines with AI clickbait nonsense](https://www.theverge.com/ai-artificial-intelligence/835839/google-discover-ai-headlines-clickbait-nonsense). Google‚Äôs Discover service is testing auto-generated, sometimes misleading or nonsensical AI-written headlines that replace publishers‚Äô originals with minimal disclosure.

#### Policy
![](https://media-cldnry.s-nbcnews.com/image/upload/t_nbcnews-fp-1200-630,f_auto,q_auto:best/rockcms/2025-11/251124-trump-rs-aae677.jpg)

[Trump signs executive order launching AI initiative being compared to the Manhattan Project](https://www.nbcnews.com/tech/tech-news/trump-signs-executive-order-launching-genesis-mission-ai-project-rcna245600). The order tasks federal agencies and industry partners with integrating vast government datasets and expanded supercomputing resources into a centralized ‚ÄúAmerican Science and Security Platform‚Äù led by Michael Kratsios to train scientific foundation models and target applications like advanced manufacturing, biotech, and nuclear energy within set 90- and 270-day timelines.

[OpenAI Ordered to Hand Over 20M ChatGPT Logs in NYT Copyright Case - Decrypt](https://decrypt-co.cdn.ampproject.org/v/s/decrypt.co/351000/openai-ordered-20m-chatgpt-logs-nyt-copyright-case). None

[California‚Äôs ban on self-driving trucks could soon be over](https://techcrunch.com/2025/12/04/californias-ban-on-self-driving-trucks-could-soon-be-over/). The DMV's revised rules would let companies test and eventually deploy driverless heavy-duty trucks on California highways through a phased permitting process with required mileage testing, reporting updates, and potential law-enforcement ticketing provisions.

#### Analysis
![](https://futurism.com/wp-content/uploads/2025/12/ai-powered-browsers-failing.jpg?quality=85&w=1200)

[AI-Powered Browsers Are Failing Badly](https://futurism.com/future-society/ai-powered-browsers-failing). These tools are slow, error-prone, require careful prompt-crafting and close supervision to be useful, and introduce meaningful security risks like prompt-injection attacks.

<hr>

Copyright ¬© 2024 Skynet Today, All rights reserved.