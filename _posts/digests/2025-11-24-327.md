---
layout: redirect
title: "Last Week in AI #327"
excerpt: "Google‚Äôs Gemini 3 shatters benchmarks ‚ö°Ô∏è, OpenAI unveils 24‚Äëhour Codex agent üõ†Ô∏è, Anthropic‚Äôs Opus 4.5 lands Chrome/Excel boosts üß©, Google‚Äôs Nano Banana Pro levels up images üçåüñºÔ∏è, Nvidia touts ‚Äòcrazy good‚Äô Q4 üöÄ, and more!"
image: 
  feature: assets/img/digests/327/nvidia-ceo-jensen-huang.jpg?ve=1&tl=1
  credit: <a href="<Image Source Link>"> <Author> / <Source Name> </a>
categories: [digests]
permalink: /digests/the-three-hundred-and-twenty-seventh
sidebartoc: true
redirect: https://lastweekin.ai/p/327
---### Top News

#### [Google launches Gemini 3 with new coding app and record benchmark scores](https://techcrunch.com/2025/11/18/google-launches-gemini-3-with-new-coding-app-and-record-benchmark-scores/)
Related:
 * [Alphabet stock surges on Gemini 3 AI model optimism](https://www.cnbc.com/2025/11/19/alphabet-stock-gemini-3-ai.html)
 * [Alphabet races toward $4 trillion valuation as AI-fueled gains accelerate](https://finance.yahoo.com/news/alphabet-races-toward-4-trillion-154219877.html)

![](https://techcrunch.com/wp-content/uploads/2025/10/gemini.jpg?resize=1200,800)

Google unveiled Gemini 3, its most capable foundation model to date, now live in the Gemini app and AI Search, with a research-tier Gemini 3 Deepthink coming to AI Ultra subscribers after additional safety testing. Google cites a ‚Äúmassive jump in reasoning,‚Äù reflected in record results: 37.4 on Humanity‚Äôs Last Exam (topping GPT‚Äë5 Pro‚Äôs 31.64) and the top spot on LMArena‚Äôs human satisfaction leaderboard. The release introduces Google Antigravity, a Gemini-powered, agentic coding interface that blends a prompt window, terminal, and browser to iteratively build and run code‚Äîakin to Warp or Cursor 2.0‚Äîwith multi‚Äëpane workflows across editor, terminal, and browser. Google also notes the Gemini app has 650 million MAUs and 13 million developers using the model, and positions Gemini 3 as requiring less prompting while handling more complex queries and context.

Markets responded quickly: Alphabet shares rose about 3% on launch day, then climbed more than 5% to a record $315.9, lifting its market cap to roughly $3.82T and putting it near the $4T mark. Analysts at D.A. Davidson called Gemini 3 ‚Äústate-of-the-art,‚Äù citing early testing and benchmarks. Reporting points to Alphabet‚Äôs strengthening cloud business, in-house AI chips as alternatives to Nvidia‚Äôs GPUs, and early positive reception for Gemini 3, with Berkshire Hathaway‚Äôs stake adding to investor confidence. While some warn of bubble risks amid circular AI deals and lofty valuations, coverage emphasizes Google‚Äôs integration of Gemini 3 across Search, the app, and enterprise services as a tangible driver of AI-fueled gains.

#### [OpenAI releases GPT-5.1-Codex-Max to handle engineering tasks that span twenty-four hours](https://the-decoder.com/openai-releases-gpt-5-1-codex-max-to-handle-engineering-tasks-that-span-twenty-four-hours/)
![](https://the-decoder.com/wp-content/uploads/2025/11/codex_max_logo.png)

OpenAI launched GPT-5.1-Codex-Max, an ‚Äúagentic‚Äù coding model built for long-running, detailed engineering work and large context handling, replacing GPT-5.1-Codex as the default across Codex interfaces. On benchmarks, it posts 77.9% on SWE-Bench Verified (n=500), leading Anthropic and Google‚Äôs latest, and boosts OpenAI‚Äôs internal SWE-Lancer IC SWE from 66.3% to 79.9%; it also records 58.1% on TerminalBench 2.0. The model uses 30% fewer ‚Äúthinking tokens‚Äù than its predecessor while running 27‚Äì42% faster on real-world tasks; an Extra High reasoning mode is available when latency is less critical. Notably, it‚Äôs the first Codex model trained specifically for Windows environments to better handle command-line workflows. Access is rolling out to ChatGPT Plus, Pro, Team, Edu, and Enterprise now, with Plus capped at 45‚Äì225 local messages and 10‚Äì60 cloud tasks per 5 hours, and Pro at 300‚Äì1,500 local and 50‚Äì400 cloud; API access and pricing (previously $1.25/M input, $10/M output for the old model) are pending.

A new ‚Äúcompaction‚Äù process enables day-long coding sessions by automatically summarizing and compressing session history when the context window fills, retaining relevant steps across millions of tokens. GPT-5.1-Codex-Max is the first model natively trained to operate across multiple context windows in this way. OpenAI claims the agent can stay focused on a single task for over 24 hours in internal tests, tackling issues like fixing test failures or iterating on implementations. The company reports 95% internal engineer adoption of Codex and a 70% increase in pull requests since its introduction. On security, OpenAI says this is its most capable cybersecurity model yet but still below its internal ‚ÄúHigh Capability‚Äù threshold; it advises developers to treat Codex as an additional reviewer, verify outputs before deployment, and use terminal logs with tool-call citations and test results to audit long-running work.

#### [Anthropic releases Opus 4.5 with new Chrome and Excel integrations](https://techcrunch.com/2025/11/24/anthropic-releases-opus-4-5-with-new-chrome-and-excel-integrations/)
![](https://techcrunch.com/wp-content/uploads/2025/11/Claude-Opus-4.5-illustration.png?resize=1200,675)

Anthropic released Opus 4.5, its top Claude model, claiming state-of-the-art results across coding (SWE-Bench, Terminal-bench), tool use (tau2-bench, MCP Atlas), and general reasoning (ARC-AGI 2, GPQA Diamond). It‚Äôs the first model to surpass 80% on SWE-Bench Verified, a strong signal of end-to-end code problem solving. The launch includes broader availability of Claude for Chrome and Claude for Excel: the Chrome extension rolls out to Max users, while the Excel-focused product is available to Max, Team, and Enterprise tiers. Anthropic highlights improved ‚Äúcomputer use‚Äù and spreadsheet workflows as core strengths, positioning Opus 4.5 for hands-on software and data tasks.

Long-context reliability and memory are major focuses. Beyond larger context windows, Anthropic reworked memory management so the model better decides what to retain, enabling an ‚Äúendless chat‚Äù feature that compresses context silently when limits are reached. These upgrades target agentic use cases where Opus orchestrates Haiku-powered sub-agents, requiring robust working memory to explore large codebases, navigate lengthy documents, backtrack, and re-verify results. Opus 4.5 emphasizes practical tool use and multi-step control alongside benchmark gains, directly competing with OpenAI‚Äôs GPT‚Äë5.1 and Google‚Äôs Gemini 3.

#### [Google launches Nano Banana Pro, an updated AI image generator powered by Gemini 3](https://www.cnbc.com/2025/11/20/google-nano-banana-pro-gemini-3.html)
![](https://image.cnbcfm.com/api/v1/image/108229109-1763647315089-gettyimages-2235972134-avdtnmysept25lot8g.jpeg?v=1763647342&w=1920&h=1080)

Google introduced Nano Banana Pro, an upgraded AI image editing and generation tool powered by Gemini 3 Pro, just days after unveiling the new Gemini model. The update goes beyond the original viral Nano Banana by supporting multi-image composition and character consistency: it can accept up to 14 different images or maintain five distinct characters across outputs. According to Google‚Äôs Josh Woodward, it‚Äôs ‚Äúincredible at infographics,‚Äù and can generate slide decks and visualizations from non-visual inputs such as code snippets and LinkedIn resumes. The product expands the use case from 3D figurine-style edits to structured visual content creation, emphasizing layout, consistency, and data-driven visuals.

Availability spans the Gemini app with limited free quotas, NotebookLM, and Google‚Äôs developer, enterprise, and advertising products; Google AI Pro and Ultra subscribers can also access it via Search‚Äôs AI Mode. The tool‚Äôs release follows the Gemini 3 Pro announcement, which helped propel Alphabet‚Äôs stock to record highs, rising 4% on Thursday. Woodward shared internal experiments showing strong performance for infographic generation and character coherence across inputs, suggesting improved prompt-to-visual fidelity. The original Nano Banana spurred rapid adoption, adding 13 million Gemini app users in four days, and the Pro version aims to extend that momentum into productivity workflows like slides, marketing assets, and data visualization.

#### [Nvidia CEO predicts 'crazy good' fourth quarter after strong earnings calm AI bubble fears](https://www.foxbusiness.com/markets/nvidia-ceo-predicts-crazy-good-q4-strong-earnings-calm-ai-bubble-fears)
![](https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2025/11/0/0/nvidia-ceo-jensen-huang.jpg?ve=1&tl=1)

Nvidia CEO Jensen Huang said the company is heading into a ‚Äúcrazy good‚Äù fiscal Q4 after delivering stronger-than-expected Q3 results, emphasizing sustained demand for AI infrastructure. Nvidia guided Q4 revenue to $65 billion ¬±2% versus $61.66 billion expected and forecast an adjusted gross margin of about 75% ¬±50 bps, with plans to keep margins in the mid‚Äë70% through fiscal 2027, according to CFO Colette Kress. Q3 sales rose 62%, the first acceleration in seven quarters, driven by data-center revenue of $51.2 billion versus $48.62 billion expected. Huang reiterated Nvidia has roughly $500 billion in bookings for advanced AI chips through 2026 and said the multiyear buildout of ‚Äúaccelerated computing‚Äù and AI is modernizing global compute infrastructure.

Responding to concerns of ‚Äúcircular‚Äù deals, Huang said Nvidia hasn‚Äôt invested any money yet in firms like OpenAI and that none of its projected revenue includes such investments; he added OpenAI, Anthropic, and xAI raise funding independently and their rounds have been oversubscribed. Shares rose about 5% after hours, adding roughly $220 billion in market cap, lifting peers AMD and mega-cap customers Alphabet and Microsoft, and boosting S&P 500 futures by 1%. Nvidia‚Äôs stock‚Äîup 35% year-to-date after a 1,200% three-year surge‚Äîhad slipped nearly 8% in November amid bubble fears, which the results helped calm. Nvidia remains a top weight in major ETFs‚Äîapproximately 10% of QQQ and 8% of SPY and VOO‚Äîand is the largest stock in the S&P 500, amplifying its market impact.



### Other News
#### Tools
![](https://www.marktechpost.com/wp-content/uploads/2025/11/blog-banner-3-1-1024x731.png)

[Meta AI Releases Segment Anything Model 3 (SAM 3) for Promptable Concept Segmentation in Images and Videos](https://www.marktechpost.com/2025/11/20/meta-ai-releases-segment-anything-model-3-sam-3-for-promptable-concept-segmentation-in-images-and-videos/). The model can detect, segment, and track every instance of open-vocabulary concepts in images and long videos using text phrases and visual exemplars. It‚Äôs supported by a new SA-Co dataset of ~270K evaluated concepts and over 4M auto-annotated examples, plus an 848M-parameter DETR-based detector and tracker with a presence token for improved precision.

[Google is introducing its own version of Apple‚Äôs private AI cloud compute](https://www.theverge.com/news/818364/google-private-ai-compute). Called Private AI Compute, the service routes demanding AI tasks from devices to a secure cloud enclave so users can access more powerful, personalized features while, Google says, sensitive data remains inaccessible to anyone else‚Äîincluding Google.

[Google will let users call stores, browse products, and check out using AI](https://www.theverge.com/news/819431/google-shopping-ai-gemini-agentic-checkout-calling). New tools enable conversational product searches, let an AI call local stores for stock and deals, and authorize an AI to automatically buy items when prices hit a set threshold.

[Baidu Unveils ERNIE 5.0 and a Series of AI Applications at Baidu World 2025, Ramps Up Global Push](https://www.prnewswire.com/news-releases/baidu-unveils-ernie-5-0-and-a-series-of-ai-applications-at-baidu-world-2025--ramps-up-global-push-302614531.html). The company showcased upgrades across its AI portfolio‚Äîincluding the natively omni-modal ERNIE 5.0, new and improved digital human and agent products like Famou and GenFlow 3.0, global rollouts for tools such as MeDo and Oreate‚Äîand reported Apollo Go has completed over 17 million driverless rides.

[Fei-Fei Li‚Äôs World Labs speeds up the world model race with Marble, its first commercial product](https://techcrunch.com/2025/11/12/fei-fei-lis-world-labs-speeds-up-the-world-model-race-with-marble-its-first-commercial-product/). Marble converts text, images, videos, 3D layouts, or panoramas into persistent, downloadable 3D environments with AI-native editing tools, multi-input support, scene expansion, and export options for game, VFX, VR, and simulation workflows.

[Watch Google DeepMind‚Äôs new AI agent learn to play video games](https://www.theverge.com/tech/819937/google-deepmind-ai-agent-sima-2-agi-video-games). The agent, called SIMA 2, combines DeepMind‚Äôs prior multiworld system with Google‚Äôs Gemini to interpret high-level goals, perform complex reasoning, and take skillful actions in unseen games. It‚Äôs available as a limited research preview for academics and developers.

[Baidu teases next-gen AI training, inference accelerators](https://www.theregister.com/2025/11/13/baidu_inference_training_chips/). Baidu says the new M100 inference chip and clustered Tianchi256/Tianchi512 systems (with an M300 training chip due in 2027) aim to cut inference costs, handle MoE and multi-trillion-parameter model workloads, and reduce reliance on Western accelerators.

[ChatGPT launches group chats globally](https://techcrunch.com/2025/11/20/chatgpt-launches-group-chats-globally/). The feature supports up to 20 invited users collaborating with each other and ChatGPT in a shared conversation‚Äîwhere the AI can search, summarize, react with emojis, and be tagged to respond‚Äîwhile personal settings and memory remain private.

[ElevenLabs‚Äô new AI marketplace lets brands use famous voices for ads](https://www.theverge.com/news/818470/elevenlabs-iconic-voice-marketplace-ai-audio). The marketplace connects brands with rights holders to license and synthesize AI‚Äëreplicated celebrity and historical voices through curated, consent‚Äëbased deals that promise transparency and compensation.

[Mozilla announces an AI ‚Äòwindow‚Äô for Firefox](https://www.theverge.com/news/820196/mozilla-firefox-ai-window-browser). Mozilla says the opt-in ‚ÄúAI Window‚Äù will be a user-controlled browsing mode with a selectable AI assistant/chatbot, built with public feedback and offered alongside private and classic windows.

#### Business
![](https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-2154160973-e1723115200227.jpg?resize=1200,673)

[Anthropic announces $50 billion data center plan](https://techcrunch.com/2025/11/12/anthropic-announces-50-billion-data-center-plan/). The deal funds custom-built Texas and New York facilities coming online in 2026 to handle Claude‚Äôs heavy compute needs, complementing Anthropic‚Äôs existing cloud partnerships with Google and Amazon.

[Alphabet stock surges on Gemini 3 AI model optimism](https://www.cnbc.com/2025/11/19/alphabet-stock-gemini-3-ai.html). Investors and analysts reacted positively to early tests and benchmark results, noting Gemini 3 produces better, more context-aware answers and will be rolled into Google‚Äôs Search, app, and enterprise offerings.

[As Google pulls ahead, OpenAI's comeback plan is codenamed 'Shallotpeat'](https://the-decoder.com/as-google-pulls-ahead-openais-comeback-plan-is-codenamed-shallotpeat/). The company is developing a new model, codenamed ‚ÄúShallotpeat,‚Äù to fix pre-training bugs and catch up to Google‚Äôs Gemini 3 after Sam Altman warned staff the gap could cause short-term economic headwinds.

[Uneasiness Over A.I. Spending Looms Over Markets - The New York Times](https://www.nytimes.com/2025/11/20/business/stocks-ai-global.html). None

[Leaked documents shed light into how much OpenAI pays Microsoft](https://techcrunch.com/2025/11/14/leaked-documents-shed-light-into-how-much-openai-pays-microsoft/). Documents suggest OpenAI paid Microsoft hundreds of millions in revenue-share payments (about $494M in 2024 and $866M in the first nine months of 2025) while incurring many billions in inference compute costs that may exceed its reported revenues.

[Jeff Bezos reportedly returns to the trenches as co-CEO of new AI startup, Project Prometheus](https://techcrunch.com/2025/11/17/jeff-bezos-reportedly-returns-to-the-trenches-as-co-ceo-of-new-ai-startup-project-prometheus/). The startup, backed with $6.2 billion and staffed by nearly 100 AI researchers from firms like Meta, OpenAI, and DeepMind, will focus on building AI tools that simulate and design for engineering and manufacturing across sectors such as computers, aerospace, and automobiles.

[Coding assistant Cursor raises $2.3B 5 months after its previous round](https://techcrunch.com/2025/11/13/coding-assistant-cursor-raises-2-3b-5-months-after-its-previous-round/). The new funding, led by Accel and Coatue with participation from Nvidia and Google, will support development of Cursor‚Äôs Composer model so the company can reduce reliance on third-party AI models amid rising competition from OpenAI and Anthropic.

[Saudi Arabia Backs Elon Musk‚Äôs xAI With Data Center Deal - The New York Times](https://www.nytimes.com/2025/11/19/technology/saudi-arabia-elon-musk-xai.html). None

[Robotics Startup Physical Intelligence Valued at $5.6 Billion in New Funding - Bloomberg](https://www.bloomberg.com/news/articles/2025-11-20/robotics-startup-physical-intelligence-valued-at-5-6-billion-in-new-funding). None

[Waymo permitted areas expanded by California DMV](https://www.cbsnews.com/losangeles/video/waymo-permitted-areas-expanded-by-california-dmv/). New approval lets Waymo run its driverless operations across the full Bay Area, Sacramento, and almost all of Southern California up to the Mexican border.

[Waymo enters 3 more cities: Minneapolis, New Orleans, and Tampa](https://techcrunch.com/2025/11/20/waymo-enters-3-more-cities-minneapolis-new-orleans-and-tampa/). Waymo will begin manually driving and testing its vehicles in those cities as part of validation before aiming to deploy commercial robotaxi services, while facing local challenges like Minneapolis snow and New Orleans‚Äô narrow, pedestrian-heavy streets.

[Warner Music Group Settles AI Infringement Lawsuit With Udio](https://www.hollywoodreporter.com/music/music-industry-news/warner-music-group-settles-lawsuit-udio-1236431207/). The settlement paves the way for Udio‚Äôs 2026 platform to offer licensed WMG recordings and publishing, includes opt-in artist participation with fingerprinting/filtering safeguards, and follows a similar deal Udio made with Universal while Sony remains in litigation.

#### Research
![](https://www.marktechpost.com/wp-content/uploads/2025/11/blog-banner-45-1024x731.png)

[OpenAI Researchers Train Weight Sparse Transformers to Expose Interpretable Circuits](https://www.marktechpost.com/2025/11/14/openai-researchers-train-weight-sparse-transformers-to-expose-interpretable-circuits/). The team enforces extreme weight sparsity during training (keeping roughly 1 in 1,000 weights) and measures interpretability by finding minimal task-specific subnetworks, showing much smaller, often fully reverse-engineerable circuits for Python next-token tasks compared with dense models.

[RLVE: Scaling Up Reinforcement Learning for Language Models with Adaptive Verifiable Environments](https://arxiv.org/abs/2511.07317). This work uses procedurally generated, algorithmically verifiable environments with adaptive difficulty (RLVE-Gym‚Äôs 400 tasks) to provide scalable, continuously challenging RL training that improves reasoning performance and data efficiency compared to static datasets like DeepMath-103K.

[Think-at-Hard: Selective Latent Iterations to Improve Reasoning Language Models](https://arxiv.org/abs/2511.08577). The method employs a neural decider, duo-causal attention, and LoRA adapters with an oracle-guided training scheme to apply extra latent iterations only to hard-to-predict tokens, improving reasoning accuracy by ~4‚Äì5% (up to ~5.8% with three iterations) while keeping average FLOPs close to the single-iteration baseline.

[TiDAR: Think in Diffusion, Talk in Autoregression](https://arxiv.org/abs/2511.08923). The approach combines diffusion-based parallel token drafting with autoregressive rejection-sampled decoding in a single model and forward pass, reusing the KV cache and ‚Äúfree token slots‚Äù to achieve much higher throughput with similar or minimally reduced quality.

[ATLAS: A High-Difficulty, Multidisciplinary Benchmark for Frontier Scientific Reasoning](https://arxiv.org/abs/2511.14366). ATLAS provides a contamination-resistant, expert-crafted set of ~800 high-difficulty, multidisciplinary scientific problems (targeting <20% pass rate) along with a scalable LRM-as-judge evaluation workflow and a plan for a community-driven platform.

[LoCoBench-Agent: An Interactive Benchmark for LLM Agents in Long-Context Software Engineering](https://arxiv.org/abs/2511.13998). This benchmark converts 8,000 scenarios into interactive multi-turn environments with specialized tools and nine bias-mitigated metrics to measure agents‚Äô long-context comprehension, tool-usage strategies, efficiency, and error recovery across 10K‚Äì1M token contexts.

[Adversarial Poetry as a Universal Single-Turn Jailbreak Mechanism in Large Language Models](https://arxiv.org/abs/2511.15304). The study finds that reformulating harmful prompts into poetic verse drastically increases jailbreak success‚Äîraising attack-success rates up to threefold and averaging 62% across 25 major models‚Äîindicating poetic structure itself reliably undermines safety controls across providers and domains.

[Instella: Fully Open Language Models with Stellar Performance](https://arxiv.org/abs/2511.10628). The project releases the full training pipeline, datasets, and recipes for a 3B-parameter LLM family‚Äîincluding a two-stage pretraining with a 57B-token reasoning-focused pass, synthetic math data, weight ensembling, supervised fine-tuning and DPO, a 128K-token long-context variant, and a math-focused RL-tuned model‚Äîclaiming competitive performance among fully open models.

[Back to Basics: Let Denoising Generative Models Denoise](https://arxiv.org/abs/2511.13720). The authors show that training plain Vision Transformers to directly predict clean images in pixel space (x-prediction) yields strong diffusion models without pretraining, latents, or auxiliary losses, often outperforming Œµ- and v-prediction and enabling self-contained ‚ÄúDiffusion + Transformer‚Äù modeling.

[LeJEPA: Provable and Scalable Self-Supervised Learning Without the Heuristics](https://arxiv.org/abs/2511.08544). LeJEPA introduces Sketched Isotropic Gaussian Regularization as a principled training objective for joint-embedding predictive architectures, improving embedding quality and stability across architectures and datasets.

[SAM 3D: 3Dfy Anything in Images](https://arxiv.org/abs/2511.16624). The model reconstructs 3D objects from single images by combining synthetic pretraining with real-world alignment in a multi-stage training pipeline and outperforms baselines in human preference evaluations.

[OlmoEarth: Stable Latent Image Modeling for Multimodal Earth Observation](https://arxiv.org/abs/2511.13655). A training method called Latent MIM Lite stabilizes latent-space self-supervised learning for multimodal satellite and sensor data; the team evaluates OlmoEarth across research benchmarks and nonprofit use cases, deploying it in an open platform for conservation and humanitarian partners.

[A new AI benchmark tests whether chatbots protect human well-being](https://techcrunch.com/2025/11/24/a-new-ai-benchmark-tests-whether-chatbots-protect-human-wellbeing/). The HumaneBench benchmark tested 15 popular models across 800 realistic scenarios and found most models improved when prompted to prioritize well-being, but 67% became actively harmful under adversarial instructions, with only a few (like GPT‚Äë5, GPT‚Äë5.1, Claude 4.1, and Sonnet 4.5) maintaining protections.

#### Concerns
![](https://platform.theverge.com/wp-content/uploads/sites/2/2025/08/STKB364_CLAUDE_A.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200)

[Hackers use Anthropic‚Äôs AI model Claude once again](https://www.theverge.com/news/820458/hackers-china-ai-anthropic-claude). Anthropic says China-linked hackers used Claude to automate about 30 cyberattacks in September‚Äîhandling 80‚Äì90% of the work and stealing sensitive data from four victims while involving humans only for a few approvals.

[The First Large-Scale Cyberattack by AI - WSJ](https://www.wsj.com/opinion/the-first-large-scale-cyberattack-by-ai-4a1e1a30). None

[What OpenAI Did When ChatGPT Users Lost Touch With Reality - The New York Times](https://www.nytimes.com/2025/11/23/technology/openai-chatgpt-users-risks.html). None

[OpenAI Locks Down San Francisco Offices Following Alleged Threat From Activist](https://www.wired.com/story/openai-office-lockdown-threat-san-francisco/). Employees were ordered to shelter in place and take security precautions after police received a 911 report alleging the named individual‚Äîpreviously linked to Stop AI‚Äîthreatened violence and had been seen at OpenAI‚Äôs San Francisco facilities.

#### Policy
![](https://platform.theverge.com/wp-content/uploads/sites/2/2025/03/STK450_EU_E.jpg?quality=90&strip=all&crop=0%2C9.9676601489831%2C100%2C80.064679702034&w=1200)

[Europe is scaling back its landmark privacy and AI laws](https://www.theverge.com/news/823750/european-union-ai-act-gdpr-changes). The Commission‚Äôs proposals would loosen GDPR limits on using anonymized and pseudonymized personal data for AI training, delay stricter rules for high-risk AI systems, simplify compliance for smaller firms, and reduce cookie pop-ups while centralizing AI oversight.

[Court rules that OpenAI violated German copyright law; orders it to pay damages](https://techcrunch.com/2025/11/12/court-rules-that-openai-violated-german-copyright-law-ordered-it-to-pay-damages/). The court found OpenAI used licensed musical works to train ChatGPT without permission, awarding damages to GEMA; OpenAI said it disagrees and may appeal.

<hr>

Copyright ¬© 2024 Skynet Today, All rights reserved.